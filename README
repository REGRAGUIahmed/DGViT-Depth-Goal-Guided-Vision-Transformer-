DGViT: Depth-Goal-Guided Vision Transformer

DGViT is a state-of-the-art visual navigation model for mobile robots. It leverages the global receptive field of Vision Transformers and the spatial robustness of depth imagery to achieve stable, goal-directed navigation in complex environments.
üåü Overview

    Architecture: Integration of Transformers for long-range environmental perception.

    Input: Raw depth images from a single Fisheye camera and goal coordinates in a polar system.

    Robustness: Trained to handle noisy sensor data for seamless Sim-to-Real transition.

    Platform: Car-like mobile robot implemented in ROS2 Humble and Gazebo.

üìΩÔ∏è Simulation Previews
Training Environments

<p align="center"> <img src="https://github.com/REGRAGUIahmed/DGViT-Depth-Goal-Guided-Vision-Transformer/blob/master/Materials/tr1.gif" width="32%" /> <img src="https://github.com/REGRAGUIahmed/DGViT-Depth-Goal-Guided-Vision-Transformer/blob/master/Materials/tr2.gif" width="32%" /> <img src="https://github.com/REGRAGUIahmed/DGViT-Depth-Goal-Guided-Vision-Transformer/blob/master/Materials/tr3.gif" width="32%" /> </p>
Unseen (Test) Environments

<p align="center"> <img src="https://github.com/REGRAGUIahmed/DGViT-Depth-Goal-Guided-Vision-Transformer/blob/master/Materials/test1.gif" width="48%" /> <img src="https://github.com/REGRAGUIahmed/DGViT-Depth-Goal-Guided-Vision-Transformer/blob/master/Materials/test2.gif" width="48%" /> </p>
üèóÔ∏è Technical Framework
Core Architecture

The model utilizes a cross-modal attention mechanism to fuse depth features with target goal information.

<p align="center"> <img src="https://github.com/REGRAGUIahmed/DGViT-Depth-Goal-Guided-Vision-Transformer/blob/master/Materials/DGVit_final.png" width="85%"> </p>
Noise-Augmented Perception

To improve generalization, depth images are augmented with synthetic noise during training.

<p align="center"> <img src="https://github.com/REGRAGUIahmed/DGViT-Depth-Goal-Guided-Vision-Transformer/blob/master/Materials/noise_image_final.png" width="65%"> </p>
‚öôÔ∏è Installation & Setup
1. Prerequisites

Ensure you have the following installed:

    Ubuntu 22.04

    ROS2 Humble

    Gazebo Fortress

2. Environment Setup

We recommend using Conda for Python dependency management:
Bash

# Create and activate environment
conda create -n dgvit python=3.10 -y
conda activate dgvit

# Install Python dependencies
pip install numpy tqdm natsort cpprb matplotlib einops squaternion opencv-python rospkg rosnumpy pyyaml

# Install ROS2 system dependencies
sudo apt install python3-colcon-common-extensions ros-humble-cv-bridge -y

3. Workspace Configuration
Bash

# Create workspace
mkdir -p ~/vis_to_nav/src
cd ~/vis_to_nav/src

# Clone the repository
git clone https://github.com/REGRAGUIahmed/DGViT-Depth-Goal-Guided-Vision-Transformer-.git

# Build the workspace
cd ~/vis_to_nav
colcon build --symlink-install
source install/setup.bash

üöÄ Running the Model
Path Modification

Before running, update the system paths in main.py and env_lab.py:
Python

# In main.py
import sys
sys.path.append('/home/<your_user>/vis_to_nav/src/DGViT-Depth-Goal-Guided-Vision-Transformer/src/vis_nav/vis_nav')

Start Training

Launch the Gazebo simulation and the training node:
Bash

source install/setup.bash
ros2 launch DGViT-Depth-Goal-Guided-Vision-Transformer training.launch.py

üõ†Ô∏è Troubleshooting

To force-stop all ROS2 and Gazebo processes, use the following alias or command:
Bash

# Direct command
killall -9 rosout roslaunch rosmaster gzserver nodelet robot_state_publisher gzclient python python3

# Recommended alias (add to ~/.bashrc)
alias k9='killall -9 rosout roslaunch rosmaster gzserver nodelet robot_state_publisher gzclient python python3'

üìñ Citation

If you find this work useful for your research, please cite our paper:
Extrait de code

@article{regragui2026dgvit,
  title={DGViT: Depth-Goal-Guided Vision Transformer for Mobile Robot Navigation},
  author={Ahmed Regragui},
  journal={Article in Revision},
  year={2026}
}
